{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Notebook_ExtraccionDeEntidades.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNXR6SIRdB10s5UTe8TSmrZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"rH_--GRYU6mW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629693850835,"user_tz":300,"elapsed":1805,"user":{"displayName":"Ramon Aparicio García","photoUrl":"","userId":"18188158073522169855"}},"outputId":"59ff7988-534e-4046-99fa-e73e0ae72ece"},"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","import os\n","import cv2\n","import imutils\n","import matplotlib.pyplot as plt\n","import re\n","from nltk.corpus import stopwords\n","from IPython.display import clear_output, display\n","import time\n","\n","# Montamos el Drive al Notebook\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","nltk.download(\"punkt\")\n","nltk.download('cess_esp')\n","nltk.download('stopwords')\n","\n","os.chdir(\"/content/drive/My Drive/Hackaton2021/codigo/pruebas/Analisis_texto/\")\n","\n","import spaghetti as sgt"],"execution_count":121,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]   Package cess_esp is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2TscgeY4VtsG","executionInfo":{"status":"ok","timestamp":1629693855965,"user_tz":300,"elapsed":281,"user":{"displayName":"Ramon Aparicio García","photoUrl":"","userId":"18188158073522169855"}}},"source":["#@title Funciones\n","def split_text(BigString):\n","    \"\"\"Split texto completo por retornos de carro o signos de puntuacion.\"\"\"\n","    pruebat = BigString\n","    splited = re.split(\"[\\,\\.]\\n\", pruebat)\n","    return splited\n","\n","def etiqueta_RIIA(word):\n","    \"\"\"Etiquetar palabras completas con cadenas posibles\"\"\"\n","    try:\n","        expr = re.compile(\".*{0}.*\".format(word))\n","        busca_coincidencia = lambda lista, expr: list(filter(lambda x: expr.match(x), lista))\n","        newtag = []\n","        for optiontag, lista in zip([\"per\", \"per\", \"pla\", \"org\"] , [listProsecuted, listcivilservs, listplaces, listorgs]):\n","            if any(busca_coincidencia(lista, expr)) and optiontag not in newtag:\n","                newtag.append(optiontag)\n","        if len(newtag) == 0:\n","            newtag = [\"dato\"]\n","    except Exception as error:\n","        print(error)\n","        print(\"Causada por:\", word)\n","        newtag = [\"Err\"]\n","    finally:\n","        return \"\".join(newtag)\n","\n","def etiqueta_simbolo(word):\n","    \"\"\"Etiquetar palabras que no hayan sido etiquetadas pos corpus.\"\"\"\n","    numeric_expr = re.compile(\"\\d+$\")\n","    alphanum_expr = re.compile(\"[\\w\\d]+\")\n","    char_expr = re.compile(\"\\w+$\")\n","    symbol_expr = re.compile(\"\\W*.*\")\n","    if numeric_expr.match(word) is not None:\n","        newtag = \"numero\"\n","    elif char_expr.match(word) is not None:\n","        newtag = \"plbr\"\n","    elif alphanum_expr.match(word) is not None:\n","        newtag = \"datoN\"\n","    elif symbol_expr.match(word) is not None:\n","        newtag = \"unknown\"\n","    else:\n","        newtag = None\n","    return newtag\n","\n","def etiqueta_entidades_RIIA(word, currtag):\n","    \"\"\"Seleccion de etiqueta de simbolo o palabra en RIIA.\"\"\"\n","    if (currtag is None) and (len(word) >= 4):\n","        newtag = etiqueta_RIIA(word)\n","    else:\n","        newtag = etiqueta_simbolo(word)\n","    return newtag\n","\n","def tagging(phrase):\n","    \"\"\"Generar tags para palabras de una frase.\"\"\"\n","    limpiar = lambda x: re.sub(\"[*+/\\-_\\\\\\?\\'\\\\\\n\\|]\", \"\", x)\n","    phrase = limpiar(phrase)\n","    tokens = nltk.word_tokenize(phrase)\n","    # limpiar palabras raras\n","    norare = lambda x: re.search(r\"[^a-zA-ZÀ-ÿ\\d]\", x) is None or len(x) > 3\n","    # quitar stopwords\n","    noincluir = stopwords.words(\"spanish\")\n","    seincluye = lambda x: ((x not in noincluir) or (x.isupper() or x.istitle())) and (norare(x))\n","    tokens = list(filter(lambda x: seincluye(x), tokens))\n","    tokens_low = list(map(lambda x: x.lower(), tokens))\n","    tagged = sgt.pos_tag(tokens_low)\n","    # filtrar los que resulten None\n","    result = []\n","    for (word, tag), word_unch in zip(tagged, tokens):\n","        if (tag is None) or (tag == \"\"):\n","            # compararlos con las entidades que se tienen de propuesta\n","            newtag = etiqueta_entidades_RIIA(word, tag)\n","            result.append((word_unch, word, newtag))\n","        else:\n","            result.append((word_unch, word, tag))\n","    return result\n","\n","def get_chunks(grammar, tagged0):\n","    \"\"\"Buscar expresion en frase mediante formulas gramaticales.\"\"\"\n","    cp = nltk.RegexpParser(grammar)\n","    #print(tagged0)\n","    tagged = list(map(lambda x: (x[1], x[2]), tagged0))\n","    chunked = cp.parse(tagged)\n","    entities = []\n","    get_position = lambda x: np.where(list(map(lambda y: x==y[0], tagged)))[0][0]\n","    entitycase = lambda ind: not(tagged0[ind][0].islower())\n","    entitytagRIIA = lambda x: re.match(r\"(per|pla|org)\\w+\", x) is not None\n","    entitycode = lambda x: x in [\"Z\", \"numero\", \"Fz\", \"datoN\"]\n","    entityplbr = lambda x: x in [\"plbr\"]\n","    for i, subtree in enumerate(chunked):\n","        if isinstance(subtree, nltk.Tree) and subtree.label() == \"NP\":\n","            inds = list(map(lambda x: get_position(x[0]), subtree.leaves()))\n","            withUppercase = list(map(lambda ind: entitycase(ind), inds))\n","            withNumbers = list(map(lambda x: entitycode(x[1]), subtree.leaves()))\n","            withtagRIIA = list(map(lambda x: entitytagRIIA(x[1]), subtree.leaves()))\n","            withplbr = list(map(lambda x: entityplbr(x[1]), subtree.leaves()))\n","            tokens = list(map(lambda ind: tagged0[ind][0], inds))\n","            tags = list(map(lambda ind: tagged0[ind][2], inds))\n","            percnum = float(np.sum(withNumbers)) / len(tokens)\n","            percplbr = float(np.sum(withplbr)) / len(tokens)\n","            if (percnum > 0.3) or (percplbr >= 0.5):\n","                entities.append((\"numb\", {\"value\":\" \".join(tokens), \"tags\": \" \".join(tags)}))\n","            elif any(withUppercase) or np.sum(withtagRIIA) >= 2:\n","                entities.append((\"1st\", {\"value\":\" \".join(tokens), \"tags\": \" \".join(tags)}))\n","            else:\n","                entities.append((\"2nd\", {\"value\":\" \".join(tokens), \"tags\": \" \".join(tags)}))\n","    return entities"],"execution_count":122,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sJzdirCaXwvd"},"source":["# Seccion Main"]},{"cell_type":"code","metadata":{"id":"QWYD8KAtVJMn","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1629693869747,"user_tz":300,"elapsed":285,"user":{"displayName":"Ramon Aparicio García","photoUrl":"","userId":"18188158073522169855"}},"outputId":"338e7c94-468d-4598-d0a2-d1c6b184a756"},"source":["#@title String fields\n","filename = \"./completos/output_fichero_manual_op2\" #@param {type:\"string\"}\n","fileoutput = \"./completos/entities_fichero_manual_op2_c3_v2\" #@param {type:\"string\"}\n","tabla = pd.read_csv(f\"{filename}.csv\", header=None)\n","strip = True #@param {type:\"boolean\"}\n","tabla"],"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4608</td>\n","      <td>3456</td>\n","      <td>../../Datos - Hackathon JusticIA/Fichas_manual...</td>\n","      <td>('RARE STORET RST Fe TT.\\n\\nTo DEL MBO. D AlOY...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4608</td>\n","      <td>3456</td>\n","      <td>../../Datos - Hackathon JusticIA/Fichas_manual...</td>\n","      <td>(' \\n    \\n\\n| ADANE\"FLORES DZRGELS™™ = 77 \\\\ ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4608</td>\n","      <td>3456</td>\n","      <td>../../Datos - Hackathon JusticIA/Fichas_manual...</td>\n","      <td>('GUEL ALLMAN, LIILIO AJCARRALA ulotro porsons...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4608</td>\n","      <td>3456</td>\n","      <td>../../Datos - Hackathon JusticIA/Fichas_manual...</td>\n","      <td>('J TR\\n- 3 ] Q = S92 e RIE [\\n\\nLJ\\n\\n13-Juni...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4608</td>\n","      <td>3456</td>\n","      <td>../../Datos - Hackathon JusticIA/Fichas_manual...</td>\n","      <td>(\"wn Eu VEIT TI JST TER\\n.\\n\\ntba dibT idl et ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>994</th>\n","      <td>4608</td>\n","      <td>3456</td>\n","      <td>../../Datos - Hackathon JusticIA/Fichas_manual...</td>\n","      <td>('tf TORIBIO PFRALTA CRESCENCIO REY™S MARGARIT...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>4608</td>\n","      <td>3456</td>\n","      <td>../../Datos - Hackathon JusticIA/Fichas_manual...</td>\n","      <td>(\"una baja se gun se dijo el ataque fue llev d...</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>4608</td>\n","      <td>3456</td>\n","      <td>../../Datos - Hackathon JusticIA/Fichas_manual...</td>\n","      <td>('ee ree eet et AY erga Smarr tb Ae 4p mn\\n\\n2...</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>4608</td>\n","      <td>3456</td>\n","      <td>../../Datos - Hackathon JusticIA/Fichas_manual...</td>\n","      <td>('LL _________________________________________...</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>4608</td>\n","      <td>3456</td>\n","      <td>../../Datos - Hackathon JusticIA/Fichas_manual...</td>\n","      <td>(\"  \\n\\nusdnoo anb sot anb ogsandsip ey KW » ©...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>999 rows × 4 columns</p>\n","</div>"],"text/plain":["        0  ...                                                  3\n","0    4608  ...  ('RARE STORET RST Fe TT.\\n\\nTo DEL MBO. D AlOY...\n","1    4608  ...  (' \\n    \\n\\n| ADANE\"FLORES DZRGELS™™ = 77 \\\\ ...\n","2    4608  ...  ('GUEL ALLMAN, LIILIO AJCARRALA ulotro porsons...\n","3    4608  ...  ('J TR\\n- 3 ] Q = S92 e RIE [\\n\\nLJ\\n\\n13-Juni...\n","4    4608  ...  (\"wn Eu VEIT TI JST TER\\n.\\n\\ntba dibT idl et ...\n","..    ...  ...                                                ...\n","994  4608  ...  ('tf TORIBIO PFRALTA CRESCENCIO REY™S MARGARIT...\n","995  4608  ...  (\"una baja se gun se dijo el ataque fue llev d...\n","996  4608  ...  ('ee ree eet et AY erga Smarr tb Ae 4p mn\\n\\n2...\n","997  4608  ...  ('LL _________________________________________...\n","998  4608  ...  (\"  \\n\\nusdnoo anb sot anb ogsandsip ey KW » ©...\n","\n","[999 rows x 4 columns]"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","metadata":{"id":"vwloiMsiXFU6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629695387989,"user_tz":300,"elapsed":1462205,"user":{"displayName":"Ramon Aparicio García","photoUrl":"","userId":"18188158073522169855"}},"outputId":"b6fed3eb-b533-4b83-f354-3cdd63ab3b0a"},"source":["grammar = r\"\"\"Q: {<per(\\w*)|(np\\w+)|nc(\\w+)|pla(\\w*)|org(\\w*)|datoN|Z|numero|Fz|plbr>}\n","              NP: {<Q> <(sp\\w+)|cc>* <Q>+}\n","              NP: {<Q>+}\n","           \"\"\"\n","\n","# posibles entidades\n","prosecuted = pd.read_csv(\"./posibles_entidades/prosecuted.csv\", sep=\"\\t\")\n","listProsecuted = prosecuted[prosecuted.columns[0]].tolist()\n","civilservs = pd.read_csv(\"./posibles_entidades/civilservants.csv\", sep=\"\\t\")\n","listcivilservs = civilservs[civilservs.columns[0]].tolist()\n","places = pd.read_csv(\"./posibles_entidades/places.csv\", sep=\"\\t\")\n","listplaces = places[places.columns[0]].tolist()\n","orgs = pd.read_csv(\"./posibles_entidades/organizations.csv\", sep=\"\\t\")\n","listorgs = orgs[orgs.columns[0]].tolist()\n","\n","nrows = tabla.shape[0]\n","begin = time.time()\n","getvalues = lambda entsarray: \"\\n\".join(list(map(lambda x: x[1][\"value\"], entsarray)))\n","dfout = pd.DataFrame(columns=[\"C1\", \"C2\", \"Imagen\", \"Texto\", \"MainEnt\", \"SecondEnt\", \"PosiblesEnt\"])\n","for irow, row in enumerate(tabla.values):\n","    clear_output(wait=True)\n","    c1 = row[0]\n","    c2 = row[1]\n","    imagen = row[2]\n","    texto = row[3]\n","    if strip:\n","        texto = texto.strip(\"(\").strip(\")\")\n","    splited = split_text(texto)\n","    entidades_texto = []\n","    for phrase in splited:\n","        if phrase != \"\":\n","            tagged = tagging(phrase)\n","            #print(\"Frase:\\n\", phrase)\n","            #print(\"tags:\\n\", tagged)\n","            entidades = get_chunks(grammar, tagged)\n","            entidades_texto.extend(entidades)\n","\n","    ent1dict = list(filter(lambda x: x[0] == \"1st\", entidades_texto))\n","    ent1values = getvalues(ent1dict)\n","    ent2dict = list(filter(lambda x: x[0] == \"2nd\", entidades_texto))\n","    ent2values = getvalues(ent2dict)\n","    entcodedict = list(filter(lambda x: x[0] == \"numb\", entidades_texto))\n","    entcodevalues = getvalues(entcodedict)\n","    newrow = {\"C1\": c1, \"C2\": c2, \"Imagen\": imagen, \"Texto\":texto,\n","              \"MainEnt\":ent1values, \"SecondEnt\": ent2values,\n","              \"PosiblesEnt\": entcodevalues}\n","    dfout = dfout.append(newrow, ignore_index=True)\n","    # print(\"Entidades:\\n\", ent1values)\n","    elapsed = time.time() - begin\n","    print(\"Porcentaje de avance {0:.2f}\\ttiempo transcurrido {1:0.4f} s\".format((irow/nrows) * 100, elapsed))\n","dfout.to_csv(f\"{fileoutput}.csv\", header=True)"],"execution_count":125,"outputs":[{"output_type":"stream","text":["Porcentaje de avance 99.90\ttiempo transcurrido 1461.6919 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HXLi2X4Ag0dQ"},"source":["# Visualizar para un texto"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8p1YNi5IB8Ia","executionInfo":{"status":"ok","timestamp":1629696010737,"user_tz":300,"elapsed":305,"user":{"displayName":"Ramon Aparicio García","photoUrl":"","userId":"18188158073522169855"}},"outputId":"42bd601e-1869-46ac-a8e1-0c3a5125cb4d"},"source":["print(dfout[\"MainEnt\"].values[9])"],"execution_count":128,"outputs":[{"output_type":"stream","text":["LOPEZ AYALA\n","LOPEZ DIAZ\n","pon ARTURO LOPEZ\n","AYALA DE LOPEZ.MARIA\n","DIAZ\n","MARTHA CROKER CANCIANO\n","AYALA DE LOPEZ\n","LOPEZ AYALA Rail\n","LOPEZ DIAZ\n","LOPEZ\n","AYALA DE LOPEZ.MARIA\n","MARTHA CROKER OF V 0\n","AYALA\n"],"name":"stdout"}]}]}