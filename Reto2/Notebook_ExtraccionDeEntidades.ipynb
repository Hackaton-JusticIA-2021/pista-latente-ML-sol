{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Notebook_ExtraccionDeEntidades.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMiUwcaaN6v8e2dxU70B7gK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"rH_--GRYU6mW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629724488006,"user_tz":300,"elapsed":29925,"user":{"displayName":"Ramon Aparicio García","photoUrl":"","userId":"18188158073522169855"}},"outputId":"a6dc77f9-cd56-4e3d-f7e9-d2a7c2896aca"},"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","import os\n","import cv2\n","import imutils\n","import matplotlib.pyplot as plt\n","import re\n","from nltk.corpus import stopwords\n","from IPython.display import clear_output, display\n","import time\n","\n","# Montamos el Drive al Notebook\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","nltk.download(\"punkt\")\n","nltk.download('cess_esp')\n","nltk.download('stopwords')\n","\n","os.chdir(\"/content/drive/My Drive/Hackaton2021/codigo/Entregables/Reto2/\")\n","\n","import spaghetti as sgt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/cess_esp.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2TscgeY4VtsG","executionInfo":{"status":"ok","timestamp":1629724743193,"user_tz":300,"elapsed":257,"user":{"displayName":"Ramon Aparicio García","photoUrl":"","userId":"18188158073522169855"}}},"source":["#@title Funciones\n","def split_text(BigString):\n","    \"\"\"Split texto completo por retornos de carro o signos de puntuacion.\"\"\"\n","    pruebat = BigString\n","    splited = re.split(\"[\\,\\.]\\n\", pruebat)\n","    return splited\n","\n","def etiqueta_RIIA(word):\n","    \"\"\"Etiquetar palabras completas con cadenas posibles\"\"\"\n","    try:\n","        expr = re.compile(\".*{0}.*\".format(word))\n","        busca_coincidencia = lambda lista, expr: list(filter(lambda x: expr.match(x), lista))\n","        newtag = []\n","        for optiontag, lista in zip([\"per\", \"per\", \"pla\", \"org\"] , [listProsecuted, listcivilservs, listplaces, listorgs]):\n","            if any(busca_coincidencia(lista, expr)) and optiontag not in newtag:\n","                newtag.append(optiontag)\n","        if len(newtag) == 0:\n","            newtag = [\"dato\"]\n","    except Exception as error:\n","        print(error)\n","        print(\"Causada por:\", word)\n","        newtag = [\"Err\"]\n","    finally:\n","        return \"\".join(newtag)\n","\n","def etiqueta_simbolo(word):\n","    \"\"\"Etiquetar palabras que no hayan sido etiquetadas pos corpus.\"\"\"\n","    numeric_expr = re.compile(\"\\d+$\")\n","    alphanum_expr = re.compile(\"[\\w\\d]+\")\n","    char_expr = re.compile(\"\\w+$\")\n","    symbol_expr = re.compile(\"\\W*.*\")\n","    if numeric_expr.match(word) is not None:\n","        newtag = \"numero\"\n","    elif char_expr.match(word) is not None:\n","        newtag = \"plbr\"\n","    elif alphanum_expr.match(word) is not None:\n","        newtag = \"datoN\"\n","    elif symbol_expr.match(word) is not None:\n","        newtag = \"unknown\"\n","    else:\n","        newtag = None\n","    return newtag\n","\n","def etiqueta_entidades_RIIA(word, currtag):\n","    \"\"\"Seleccion de etiqueta de simbolo o palabra en RIIA.\"\"\"\n","    if (currtag is None) and (len(word) >= 4):\n","        newtag = etiqueta_RIIA(word)\n","    else:\n","        newtag = etiqueta_simbolo(word)\n","    return newtag\n","\n","def tagging(phrase):\n","    \"\"\"Generar tags para palabras de una frase.\"\"\"\n","    limpiar = lambda x: re.sub(\"[*+/\\-_\\\\\\?\\'\\\\\\n\\|]\", \"\", x)\n","    phrase = limpiar(phrase)\n","    tokens = nltk.word_tokenize(phrase)\n","    # limpiar palabras raras\n","    norare = lambda x: re.search(r\"[^a-zA-ZÀ-ÿ\\d]\", x) is None or len(x) > 3\n","    # quitar stopwords\n","    noincluir = stopwords.words(\"spanish\")\n","    seincluye = lambda x: ((x not in noincluir) or (x.isupper() or x.istitle())) and (norare(x))\n","    tokens = list(filter(lambda x: seincluye(x), tokens))\n","    tokens_low = list(map(lambda x: x.lower(), tokens))\n","    tagged = sgt.pos_tag(tokens_low)\n","    # filtrar los que resulten None\n","    result = []\n","    for (word, tag), word_unch in zip(tagged, tokens):\n","        if (tag is None) or (tag == \"\"):\n","            # compararlos con las entidades que se tienen de propuesta\n","            newtag = etiqueta_entidades_RIIA(word, tag)\n","            result.append((word_unch, word, newtag))\n","        else:\n","            result.append((word_unch, word, tag))\n","    return result\n","\n","def get_chunks(grammar, tagged0):\n","    \"\"\"Buscar expresion en frase mediante formulas gramaticales.\"\"\"\n","    cp = nltk.RegexpParser(grammar)\n","    #print(tagged0)\n","    tagged = list(map(lambda x: (x[1], x[2]), tagged0))\n","    chunked = cp.parse(tagged)\n","    entities = []\n","    get_position = lambda x: np.where(list(map(lambda y: x==y[0], tagged)))[0][0]\n","    entitycase = lambda ind: not(tagged0[ind][0].islower())\n","    entitytagRIIA = lambda x: re.match(r\"(per|pla|org)\\w+\", x) is not None\n","    entitycode = lambda x: x in [\"Z\", \"numero\", \"Fz\", \"datoN\"]\n","    entityplbr = lambda x: x in [\"plbr\"]\n","    for i, subtree in enumerate(chunked):\n","        if isinstance(subtree, nltk.Tree) and subtree.label() == \"NP\":\n","            inds = list(map(lambda x: get_position(x[0]), subtree.leaves()))\n","            withUppercase = list(map(lambda ind: entitycase(ind), inds))\n","            withNumbers = list(map(lambda x: entitycode(x[1]), subtree.leaves()))\n","            withtagRIIA = list(map(lambda x: entitytagRIIA(x[1]), subtree.leaves()))\n","            withplbr = list(map(lambda x: entityplbr(x[1]), subtree.leaves()))\n","            tokens = list(map(lambda ind: tagged0[ind][0], inds))\n","            tags = list(map(lambda ind: tagged0[ind][2], inds))\n","            percnum = float(np.sum(withNumbers)) / len(tokens)\n","            percplbr = float(np.sum(withplbr)) / len(tokens)\n","            if (percnum > 0.3) or (percplbr >= 0.5):\n","                entities.append((\"numb\", {\"value\":\" \".join(tokens), \"tags\": \" \".join(tags)}))\n","            elif any(withUppercase) or np.sum(withtagRIIA) >= 2:\n","                entities.append((\"1st\", {\"value\":\" \".join(tokens), \"tags\": \" \".join(tags)}))\n","            else:\n","                entities.append((\"2nd\", {\"value\":\" \".join(tokens), \"tags\": \" \".join(tags)}))\n","    return entities"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sJzdirCaXwvd"},"source":["# Seccion Main"]},{"cell_type":"code","metadata":{"id":"QWYD8KAtVJMn","colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"status":"ok","timestamp":1629724862873,"user_tz":300,"elapsed":360,"user":{"displayName":"Ramon Aparicio García","photoUrl":"","userId":"18188158073522169855"}},"outputId":"e027bcd7-dd8c-41df-9f90-dd746b7f1437"},"source":["#@title String fields\n","filename = \"./output/Evaluacion_Reto2A\" #@param {type:\"string\"}\n","fileoutput = \"./output/entities_fichero_manual_op2_c3_v2\" #@param {type:\"string\"}\n","tabla = pd.read_csv(f\"{filename}.csv\", header=None)\n","strip = False #@param {type:\"boolean\"}\n","tabla"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>filename</td>\n","      <td>text</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>../../../Datos - Hackathon JusticIA/Evaluacion...</td>\n","      <td>gan\\n\\nSK\\nanand RENCE pv I.\\n\\n'OLSA CAST.NLY...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>../../../Datos - Hackathon JusticIA/Evaluacion...</td>\n","      <td>J Ti CEE DE LP a th\\n\\n“7” MORALES LOPEZ,Delia...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>../../../Datos - Hackathon JusticIA/Evaluacion...</td>\n","      <td>SA AA 2\\n| [OVP\\n\\nron a conocer la situaciébd...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>../../../Datos - Hackathon JusticIA/Evaluacion...</td>\n","      <td>Bai LCT oF WSR ail EE EE Ppp 3\\n\\nEman ES\\n[C=...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>../../../Datos - Hackathon JusticIA/Evaluacion...</td>\n","      <td>AD =LOU= A= Lo-=\"T2,\\ni + :\\n\\nHCl IRE\\ncle ef...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>../../../Datos - Hackathon JusticIA/Evaluacion...</td>\n","      <td>i ) =\\nPERNZ LOPEZ, Sartha.- I REL\\n-13-  H-20...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>../../../Datos - Hackathon JusticIA/Evaluacion...</td>\n","      <td>-~\\n~~\\n\\n-lf\\n\\n0\\n\\n1¢minas fueron distribuf...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>../../../Datos - Hackathon JusticIA/Evaluacion...</td>\n","      <td>Be ina UV ONO WE TD th aay\\n\\n \\n\\nTambién se ...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>../../../Datos - Hackathon JusticIA/Evaluacion...</td>\n","      <td>MLETINEZ DAME Arturc Lic Ex-100-10-1-62\\n‘ Co ...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>../../../Datos - Hackathon JusticIA/Evaluacion...</td>\n","      <td>] RZ ' MET ¢ bhi | LE AL I BE bo of [RXTE of N...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    0                                                  1\n","0                                            filename                                               text\n","1   ../../../Datos - Hackathon JusticIA/Evaluacion...  gan\\n\\nSK\\nanand RENCE pv I.\\n\\n'OLSA CAST.NLY...\n","2   ../../../Datos - Hackathon JusticIA/Evaluacion...  J Ti CEE DE LP a th\\n\\n“7” MORALES LOPEZ,Delia...\n","3   ../../../Datos - Hackathon JusticIA/Evaluacion...  SA AA 2\\n| [OVP\\n\\nron a conocer la situaciébd...\n","4   ../../../Datos - Hackathon JusticIA/Evaluacion...  Bai LCT oF WSR ail EE EE Ppp 3\\n\\nEman ES\\n[C=...\n","5   ../../../Datos - Hackathon JusticIA/Evaluacion...  AD =LOU= A= Lo-=\"T2,\\ni + :\\n\\nHCl IRE\\ncle ef...\n","6   ../../../Datos - Hackathon JusticIA/Evaluacion...  i ) =\\nPERNZ LOPEZ, Sartha.- I REL\\n-13-  H-20...\n","7   ../../../Datos - Hackathon JusticIA/Evaluacion...  -~\\n~~\\n\\n-lf\\n\\n0\\n\\n1¢minas fueron distribuf...\n","8   ../../../Datos - Hackathon JusticIA/Evaluacion...  Be ina UV ONO WE TD th aay\\n\\n \\n\\nTambién se ...\n","9   ../../../Datos - Hackathon JusticIA/Evaluacion...  MLETINEZ DAME Arturc Lic Ex-100-10-1-62\\n‘ Co ...\n","10  ../../../Datos - Hackathon JusticIA/Evaluacion...  ] RZ ' MET ¢ bhi | LE AL I BE bo of [RXTE of N..."]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"vwloiMsiXFU6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629695387989,"user_tz":300,"elapsed":1462205,"user":{"displayName":"Ramon Aparicio García","photoUrl":"","userId":"18188158073522169855"}},"outputId":"b6fed3eb-b533-4b83-f354-3cdd63ab3b0a"},"source":["grammar = r\"\"\"Q: {<per(\\w*)|(np\\w+)|nc(\\w+)|pla(\\w*)|org(\\w*)|datoN|Z|numero|Fz|plbr>}\n","              NP: {<Q> <(sp\\w+)|cc>* <Q>+}\n","              NP: {<Q>+}\n","           \"\"\"\n","\n","# posibles entidades\n","prosecuted = pd.read_csv(\"./insumos/prosecuted.csv\", sep=\"\\t\")\n","listProsecuted = prosecuted[prosecuted.columns[0]].tolist()\n","civilservs = pd.read_csv(\"./insumos/civilservants.csv\", sep=\"\\t\")\n","listcivilservs = civilservs[civilservs.columns[0]].tolist()\n","places = pd.read_csv(\"./insumos/places.csv\", sep=\"\\t\")\n","listplaces = places[places.columns[0]].tolist()\n","orgs = pd.read_csv(\"./insumos/organizations.csv\", sep=\"\\t\")\n","listorgs = orgs[orgs.columns[0]].tolist()\n","\n","nrows = tabla.shape[0]\n","begin = time.time()\n","getvalues = lambda entsarray: \"\\n\".join(list(map(lambda x: x[1][\"value\"], entsarray)))\n","dfout = pd.DataFrame(columns=[\"C1\", \"C2\", \"Imagen\", \"Texto\", \"MainEnt\", \"SecondEnt\", \"PosiblesEnt\"])\n","for irow, row in enumerate(tabla.values):\n","    clear_output(wait=True)\n","    c1 = row[0]\n","    c2 = row[1]\n","    imagen = row[2]\n","    texto = row[3]\n","    if strip:\n","        texto = texto.strip(\"(\").strip(\")\")\n","    splited = split_text(texto)\n","    entidades_texto = []\n","    for phrase in splited:\n","        if phrase != \"\":\n","            tagged = tagging(phrase)\n","            #print(\"Frase:\\n\", phrase)\n","            #print(\"tags:\\n\", tagged)\n","            entidades = get_chunks(grammar, tagged)\n","            entidades_texto.extend(entidades)\n","\n","    ent1dict = list(filter(lambda x: x[0] == \"1st\", entidades_texto))\n","    ent1values = getvalues(ent1dict)\n","    ent2dict = list(filter(lambda x: x[0] == \"2nd\", entidades_texto))\n","    ent2values = getvalues(ent2dict)\n","    entcodedict = list(filter(lambda x: x[0] == \"numb\", entidades_texto))\n","    entcodevalues = getvalues(entcodedict)\n","    newrow = {\"C1\": c1, \"C2\": c2, \"Imagen\": imagen, \"Texto\":texto,\n","              \"MainEnt\":ent1values, \"SecondEnt\": ent2values,\n","              \"PosiblesEnt\": entcodevalues}\n","    dfout = dfout.append(newrow, ignore_index=True)\n","    # print(\"Entidades:\\n\", ent1values)\n","    elapsed = time.time() - begin\n","    print(\"Porcentaje de avance {0:.2f}\\ttiempo transcurrido {1:0.4f} s\".format((irow/nrows) * 100, elapsed))\n","dfout.to_csv(f\"{fileoutput}.csv\", header=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Porcentaje de avance 99.90\ttiempo transcurrido 1461.6919 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HXLi2X4Ag0dQ"},"source":["# Visualizar para un texto"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8p1YNi5IB8Ia","executionInfo":{"status":"ok","timestamp":1629696010737,"user_tz":300,"elapsed":305,"user":{"displayName":"Ramon Aparicio García","photoUrl":"","userId":"18188158073522169855"}},"outputId":"42bd601e-1869-46ac-a8e1-0c3a5125cb4d"},"source":["print(dfout[\"MainEnt\"].values[9])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LOPEZ AYALA\n","LOPEZ DIAZ\n","pon ARTURO LOPEZ\n","AYALA DE LOPEZ.MARIA\n","DIAZ\n","MARTHA CROKER CANCIANO\n","AYALA DE LOPEZ\n","LOPEZ AYALA Rail\n","LOPEZ DIAZ\n","LOPEZ\n","AYALA DE LOPEZ.MARIA\n","MARTHA CROKER OF V 0\n","AYALA\n"],"name":"stdout"}]}]}